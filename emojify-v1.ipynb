{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67f3b808",
   "metadata": {},
   "source": [
    "# Emojify - V1\n",
    "Implementaremos un modelo simple de recomendaci贸n de emojis basado en una oraci贸n de entrada ocupando Word Embeddings. Este modelo es una adaptaci贸n de la tarea \"Emojify\" del curso de Sequence Models de Andrew Ng. En esta adaptaci贸n ocuparemos Pytorch a cambio de Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a61c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aseba\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from emo_utils import *\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca23d16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
    "X_test, Y_test = read_csv('data/tesss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89075af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132,), (132,), (56,), (56,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11714ccb",
   "metadata": {},
   "source": [
    "Obtendremos los vectores de embeddings asociados a cada palabra de cada oraci贸n y el promedio ser谩 la entrada de la red.\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"arquitectura.png\" style=\"width:900px;height:300px;\">\n",
    "    <caption><center><font color='purple'>Baseline model (Emojifier-V1).</center></caption>\n",
    "</center></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce3d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_oh_train = convert_to_one_hot(Y_train, C = 5) # One hot encoding clases\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "551fcd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_oh_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a4674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0d28748",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35803df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
       "       -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
       "        2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
       "        1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
       "       -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
       "       -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
       "        4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
       "        7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
       "       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
       "        1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_vec_map['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c0ddfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, X_train, y_train, any_word):\n",
    "        self.n_samples = len(X_train)\n",
    "        self.x_data = X_train\n",
    "        self.y_data = y_train\n",
    "        self.any_word = any_word\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.x_data[idx]\n",
    "        words = sentence.lower().split() # Palabras de cada frase\n",
    "        avg = np.zeros(word_to_vec_map[self.any_word].shape) # Vector de ceros - embeddings\n",
    "        count = 0\n",
    "        for w in words:\n",
    "            if w in list(word_to_vec_map.keys()):\n",
    "                avg += word_to_vec_map[w] # Vector asociado a la palabra\n",
    "                count +=1\n",
    "        if count > 0:\n",
    "            avg = avg/count # Promedio\n",
    "        return torch.tensor(avg, dtype=torch.float32), torch.tensor(self.y_data[idx], dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b97ae675",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "dataset = Dataset(X_train, Y_oh_train, any_word = 'the')\n",
    "train_loader = DataLoader(dataset = dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8a2ad8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 50])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b654ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emojify(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = F.softmax(out, dim=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85a755e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emojify(\n",
       "  (l1): Linear(in_features=50, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 5 # N煤mero de clases\n",
    "input_size = 50 # Caracteristicas\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else 'cpu'\n",
    "model = Emojify(input_size, num_classes).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ea45ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae5c095d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10/100, loss=1.6429\n",
      "epoch 20/100, loss=1.4636\n",
      "epoch 30/100, loss=1.5762\n",
      "epoch 40/100, loss=1.3012\n",
      "epoch 50/100, loss=1.5506\n",
      "epoch 60/100, loss=1.1893\n",
      "epoch 70/100, loss=1.5244\n",
      "epoch 80/100, loss=1.3904\n",
      "epoch 90/100, loss=1.0520\n",
      "epoch 100/100, loss=1.2299\n",
      "final loss, loss = 1.2299\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for (sentence, classes) in train_loader:\n",
    "        sentence = sentence.to(device)\n",
    "        classes = classes.to(device)\n",
    "        \n",
    "        outputs = model(sentence) \n",
    "        loss = criterion(outputs, classes)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad() # gradientes en 0 para cada batch\n",
    "        loss.backward() # Gradientes\n",
    "        optimizer.step() # Actualizamos par谩metros\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'epoch {epoch + 1}/{num_epochs}, loss={loss.item():.4f}')\n",
    "        \n",
    "print(f'final loss, loss = {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b71a800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":smile:\",\n",
    "                    \"3\": \":disappointed:\",\n",
    "                    \"4\": \":fork_and_knife:\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d07fc636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i cherish you :disappointed:\n",
      "i love you わ\n",
      "funny lol :smile:\n",
      "lets play with a ball \n",
      "food is ready \n",
      "not feeling happy :smile:\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "examples = np.array([\"i cherish you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"])\n",
    "predicts = []\n",
    "for sentence in examples:\n",
    "    words = sentence.lower().split() \n",
    "    avg = np.zeros(word_to_vec_map['the'].shape)\n",
    "    count = 0\n",
    "    for w in words:\n",
    "        if w in list(word_to_vec_map.keys()):\n",
    "            avg += word_to_vec_map[w] # Vector asociado a la palabra\n",
    "            count +=1\n",
    "        if count > 0:\n",
    "            avg = avg/count # Promedio\n",
    "    avg = torch.tensor(avg, dtype=torch.float32)  \n",
    "    output = model(avg)\n",
    "    max_index = torch.argmax(output).item()\n",
    "    print(emoji.emojize(sentence + ' ' + emoji_dictionary[str(max_index)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
