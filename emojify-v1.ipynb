{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67f3b808",
   "metadata": {},
   "source": [
    "# Emojify - V1\n",
    "Implementaremos un modelo simple de recomendación de emojis basado en una oración de entrada ocupando Word Embeddings. Este modelo es una adaptación de la tarea \"Emojify\" del curso de Sequence Models de Andrew Ng. En esta adaptación ocuparemos Pytorch a cambio de Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a61c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aseba\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from emo_utils import *\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca23d16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
    "X_test, Y_test = read_csv('data/tesss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89075af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132,), (132,), (56,), (56,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11714ccb",
   "metadata": {},
   "source": [
    "Obtendremos los vectores de embeddings asociados a cada palabra de cada oración y el promedio será la entrada de la red.\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"arquitectura.png\" style=\"width:900px;height:300px;\">\n",
    "    <caption><center><font color='purple'>Baseline model (Emojifier-V1).</center></caption>\n",
    "</center></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce3d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_oh_train = convert_to_one_hot(Y_train, C = 5) # One hot encoding clases\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "551fcd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_oh_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a4674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0d28748",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35803df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
       "       -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
       "        2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
       "        1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
       "       -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
       "       -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
       "        4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
       "        7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
       "       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
       "        1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_vec_map['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c0ddfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, X_train, y_train, any_word):\n",
    "        self.n_samples = len(X_train)\n",
    "        self.x_data = X_train\n",
    "        self.y_data = y_train\n",
    "        self.any_word = any_word\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.x_data[idx]\n",
    "        words = sentence.lower().split() # Palabras de cada frase\n",
    "        avg = np.zeros(word_to_vec_map[self.any_word].shape) # Vector de ceros - embeddings\n",
    "        count = 0\n",
    "        for w in words:\n",
    "            if w in list(word_to_vec_map.keys()):\n",
    "                avg += word_to_vec_map[w] # Vector asociado a la palabra\n",
    "                count +=1\n",
    "        if count > 0:\n",
    "            avg = avg/count # Promedio\n",
    "        return torch.tensor(avg, dtype=torch.float32), torch.tensor(self.y_data[idx], dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b97ae675",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "dataset = Dataset(X_train, Y_oh_train, any_word = 'the')\n",
    "train_loader = DataLoader(dataset = dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8a2ad8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 50])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b654ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emojify(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = F.softmax(out, dim=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85a755e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emojify(\n",
       "  (l1): Linear(in_features=50, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 5 # Número de clases\n",
    "input_size = 50 # Caracteristicas\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else 'cpu'\n",
    "model = Emojify(input_size, num_classes).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ea45ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae5c095d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10/100, loss=1.6429\n",
      "epoch 20/100, loss=1.4636\n",
      "epoch 30/100, loss=1.5762\n",
      "epoch 40/100, loss=1.3012\n",
      "epoch 50/100, loss=1.5506\n",
      "epoch 60/100, loss=1.1893\n",
      "epoch 70/100, loss=1.5244\n",
      "epoch 80/100, loss=1.3904\n",
      "epoch 90/100, loss=1.0520\n",
      "epoch 100/100, loss=1.2299\n",
      "final loss, loss = 1.2299\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for (sentence, classes) in train_loader:\n",
    "        sentence = sentence.to(device)\n",
    "        classes = classes.to(device)\n",
    "        \n",
    "        outputs = model(sentence) \n",
    "        loss = criterion(outputs, classes)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad() # gradientes en 0 para cada batch\n",
    "        loss.backward() # Gradientes\n",
    "        optimizer.step() # Actualizamos parámetros\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'epoch {epoch + 1}/{num_epochs}, loss={loss.item():.4f}')\n",
    "        \n",
    "print(f'final loss, loss = {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b71a800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":smile:\",\n",
    "                    \"3\": \":disappointed:\",\n",
    "                    \"4\": \":fork_and_knife:\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d07fc636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i cherish you :disappointed:\n",
      "i love you ❤️\n",
      "funny lol :smile:\n",
      "lets play with a ball ⚾\n",
      "food is ready 🍴\n",
      "not feeling happy :smile:\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "examples = np.array([\"i cherish you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"])\n",
    "predicts = []\n",
    "for sentence in examples:\n",
    "    words = sentence.lower().split() \n",
    "    avg = np.zeros(word_to_vec_map['the'].shape)\n",
    "    count = 0\n",
    "    for w in words:\n",
    "        if w in list(word_to_vec_map.keys()):\n",
    "            avg += word_to_vec_map[w] # Vector asociado a la palabra\n",
    "            count +=1\n",
    "        if count > 0:\n",
    "            avg = avg/count # Promedio\n",
    "    avg = torch.tensor(avg, dtype=torch.float32)  \n",
    "    output = model(avg)\n",
    "    max_index = torch.argmax(output).item()\n",
    "    print(emoji.emojize(sentence + ' ' + emoji_dictionary[str(max_index)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
